{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "### Your Personal Health Expert "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Agents are systems that use an LLM as a reasoning engine to determine which actions to take and what the inputs to those actions should be.\n",
    "- The results of those actions can then be fed back into the agent and it determines whether more actions are needed, or whether it is okay to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOllama(model='llama3.2:3b', base_url='http://localhost:11434')\n",
    "llm.invoke('hi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Tools\n",
    "#### 1. Tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search Tavily for current and latest news and updates.\n",
    "        For example, stock market news, weather updates, news etc.\n",
    "    Args:\n",
    "        query: The search query.\n",
    "    \"\"\"\n",
    "    search = TavilySearchResults(\n",
    "        max_results=5,\n",
    "        search_depth=\"advanced\",\n",
    "        include_answer=True,\n",
    "        include_raw_content=True\n",
    "    )\n",
    "    response = search.invoke(query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tavily_search(\"stock market news\")\n",
    "search.invoke(\"stock market news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Health Supplements Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS \n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "embeddings = OllamaEmbeddings(model='nomic-embed-text', base_url='http://localhost:11434')\n",
    "\n",
    "db_name = r\"D:\\NLP\\LLM\\Langchain and Ollama\\09. Vector Stores and Retrievals\\health_supplements\"\n",
    "vector_store = FAISS.load_local(db_name, embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "retriever = vector_store.as_retriever(search_type = 'similarity', \n",
    "                                      search_kwargs = {'k': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def health_supplements(query: str) -> str:\n",
    "    \"\"\"Search for information about Health Supplements.\n",
    "    For any questions about Health and Gym Supplements, you must use this tool!,\n",
    "\n",
    "    Args:\n",
    "        query: The search query.\n",
    "    \"\"\"\n",
    "    response = retriever.invoke(query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the best supplement for muscle gain?\"\n",
    "health_supplements.invoke(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The agent is responsible for taking in input and deciding what actions to take\n",
    " - the Agent does not execute those actions - that is done by the AgentExecutor\n",
    " - `create_tool_calling_agent` will call `.bind_tools` for us under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_tool_calling_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search, health_supplements]\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the best supplement for muscle gain?\"\n",
    "# question = \"What's the weather in SF?\"\n",
    "\n",
    "response = agent_executor.invoke({'input': question})\n",
    "print(response['input'])\n",
    "print(\"\\n\\nOutput:\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What's the weather in SF?\"\n",
    "\n",
    "response = agent_executor.invoke({'input': question})\n",
    "print(response['input'])\n",
    "print(\"\\n\\nOutput:\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Write Report on the stock market news\"\n",
    "\n",
    "response = agent_executor.invoke({'input': question})\n",
    "print(response['input'])\n",
    "print(\"\\n\\nOutput:\")\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
